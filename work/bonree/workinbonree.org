#+title: work in bonree
* 工作日志
** 2020-02 February
*** 2020.02.17
工作时间：2020.02.17
时间范围：9:00-18：00
有效工时： 8
工作内容：
1. 9：00-10：00  1 办理入职
2. 10：00-12：00 2 从公司回家，与同事在周一会议里认识
3. 13：00-17:30 4.5处理入职后续，等待开通邮箱，等待期间熟悉brfs
4. 17：30-18：00 0.5 配置vpn [[http://www.luyixian.cn/news_show_72173.aspx][openVPN 配置]]
*** 工作时间：2020.02.18
时间范围：9：00-18：30
有效工时： 8.5
工作内容：
1. 9：00 - 10：00 1 [[http://bonreeoa.ibr.cc:8088/seeyon/bulData.do?method=userView&id=-7184086811781480265&auditFlag=0&spaceId=][公司邮箱配置]] [[http://mail.bonree.com:30001/][公司邮箱地址]] 收到会议纪要，结合设计文档，熟悉二期主要任务
2. 10：00-11：00 1 看brfs的代码
*** 工作时间：2020.02.19
时间范围：9:00-18:30
有效工时： 8.5
工作内容：
1. 9：00-12：00 3 深入brfs的代码，主要按写入流程跟踪代码
2. 13:00-14:30 1.5 继续跟踪写流程
3. 14:30-18:30 4 结合设计文档学习brfs 主要关注数据读取的实现
*** 工作时间：2020.02.20
时间范围：9:00 - 18:30
有效工时： 8
工作内容：
1. 9:00 - 10:00 1 回顾写入代码，看读取代码
2. 10：00 - 13：00 3 例会
3. 14：00 - 16：00 2 回顾hdfs的写入流程并与俞朋讨论，为大文件的写入做知识准备
4. 16：00 - 18：00 2 熟悉brfs
会议纪要
1. 磁盘检测
2. 磁盘注册
3. server选择向服务端移动
4. 副本迁移方式及迁移后的路由规则的更新方式
5. levelDB 写入1.8w qps
6. 集群恢复
7. 大文件，大小文件的存储模式差异很大。侧重点也不同。大小文件分开
*** 工作时间：2020.02.21
时间范围：9:00 - 18:00
有效工时： 8
工作内容：
1. 9:00 - 12:00 3 为去掉客户端选择服务端写数据对zk的依赖，看服务选择的流程
2. 13:00 - 16:00 3 继续看客户端服务选择的代码
3. 16：00 - 17：00 补充例会
4. 17：00 - 18：00 熟悉项目，看代码
会议纪要：
1. 磁盘检测确认
2. 大文件流程确认
3. level DB 用作文件目录
4. 副本

*** 工作时间：2020.02.24
时间范围：9：00 - 18：00
有效工时： 8
工作内容：
1. 9：00 - 12：00 3 周一例会，讨论二期功能优化设计
2. 13：00 - 18：00 5 看代码，主要看资源管理，为二期开发任务做准备

*** 工作时间：2020.02.25
时间范围：9:00-18:00
有效工时： 8
工作内容：
1. 9:00-10:30 1.5 看二期设计文档，为评审做准备
2. 13:00-13:00 2.5 评审会议
3. 14:00-18:00 4 熟悉项目，主要关注zk上的集群信息相关的代码
*** 工作时间：2020.02.26
时间范围：9:00-18:00
有效工时： 8
工作内容：
1. 9:00-12:00 3 继续看brfs中zk的使用
2. 13:00-15:00 2 在代码中梳理服务和zk的交互
3. 15:00-18:00 3 整理zk上brfs涉及到的zkpath，从代码中熟悉详细设计
*** 工作时间：2020.02.27
时间范围：9：00-18：00
有效工时： 8
工作内容：
1. 9：00 - 10：00  1 读副本自动管理模块和副本从平衡模块的文档和代码
2. 10：00 - 11：00 1 会议
3. 11：00 - 12：00 1 整理大文件写入设计文档的前期设计
4. 13 : 00 - 15 : 30 2.5 为了加入大文件写入功能，详细梳理一期写入流程，画时序图帮助理解
5. 15：30 - 16：00 0.5 GUI目录设计，即kv存储目录树。
6. 16 : 00 - 18 : 00 2 补充文件写入时序图

会议内容：
1. gui目录的设计
   1. 站位符
   2. 前面拼一个id
2. 二期详细设计
   1. 大文件详细设计文档
*** 工作时间：2020.02.28
时间范围：9:00-18:30
有效工时： 8.5
工作内容：
1. 9:00 - 10:00 1 完善文件写入时序图，明确大文件写入会上讨论的雏形。
2. 10:00 - 12:00 2 为验证目录树设计的可行性，调研rocksDB
3. 13：00 - 16：00 3 设计文档初稿，梳理一遍读写流程，明确对接原有项目的具体位置。当前文档假设存在目录树，待开会决定目录树的实现方案后再做修整。
4. 16：00 - 17：00 1 梳理目录树设计，举例说明读写流程。
5. 17：00 - 17：30 0.5 会议，敲定目录树。测试方案讨论。
6. 17：30 - 18：30 1 写目录树设计文档，周一汇报。
** 2020-03 March
*** 工作时间：2020.03.02
时间范围：9:00 - 18:00
有效工时： 8
工作内容：
1. 9 : 00 - 10：50 1.9目录树文档设计。对于目录树多次读写问题，调研rocksDB，关注有没有类似Hbase协处理器的机制，没有。
2. 10：50 - 11：10 0.3 会议
3. 11：00 - 12：00 0.8 目录树接口描述
4. 13 : 00 - 18 : 00 5 完善目录树list接口和下载接口的详细设计和时序图。
会议内容
1. 文档进度
2. 压测
*** 工作时间：2020.03.03
时间范围：9 : 00 - 18 : 00
有效工时： 8.5
工作内容：
1. 9 : 00 - 10 : 00 1 复习文档，准备评审会议
2. 10 : 00 - 11 : 00 1 补充大文件写入设计文档，主要是时序图
3. 11 : 00 -12 : 30 1.5 大文件读取设计文档和读取时序图
4. 13 ：00 - 14：00 1 目录树汇报
5. 14 : 00 - 18 : 00 4 细化大文件详细设计文档，主要是接口描述、梳理流程
*** 工作时间：2020.03.04
时间范围：9 : 00 - 18:00
有效工时： 8
工作内容：
1. 9 : 00 - 11 : 00 2 细化设计文档，细化写入步骤描述
2. 11：00 - 12 : 00 1 细化大文件读取时序图的步骤描述
3. 13 : 00 - 15 : 00 2 梳理brfs一期的写入流程，修补写入时序图
4. 15：00 - 18 ：00 3 整理文档，梳理汇报流程同时整理格式。大文件设计文档初稿完成
*** 工作时间：2020.03.05
时间范围：9 : 00 - 18:30
有效工时： 8.5
工作内容：
1. 9:00 - 10:30 1.5 微调大文件详细文档，准备例会
2. 10:30 - 12:00 1.5  例会，确定接下来的任务
3. 13:00 - 14:00 1 修改目录树设计文档
4. 14:00 - 15:00 1 调研rocksDB，为目录树测试做准备
5. 15:00 - 17:00 1 细化大文件设计文档
6. 17:00 - 18:00 1 按俞朋的问题，补充调整大文件设计文档
7. 18:00 - 18:30 0.5 整理hdfs资料
会议内容：
1. 压测
2. 文档
3. 目录树的需求是什么样的，对接在哪块，对rocksDB的使用到什么层面，访问rocksDB的逻辑是什么
4. 大文件的流式写入
工作任务
1. 目录树测试方案和实施
2. 细化文档
*** 工作时间：2020.03.06
时间范围：9 : 00 - 18:00
有效工时： 8
工作内容：
1. 9：00 - 10：00 1 安装并学习使用rocksdb，调研java访问rockdb
2. 10：00 - 12：00 2 编写目录树demo，调研rocksdb的前缀扫描方式
3. 13：00 - 14：00 1 与张奇讨论测试相关问题，前缀扫描实现方案
4. 14：00 - 15：00 1 编写测试程序
5. 15：00 - 18：00 3 测试，调整程序，记录数据，写测试报告
*** 工作时间：2020.03.09
时间范围：9 : 00 - 18:00
有效工时： 8.5
工作内容：
1. 9:00 - 10:00 1 调整写入时序图的文字描述，明确数据传递的方案。
2. 10：00 - 12：30 2.5 会议
3. 13 : 00 - 16 : 00 3 rocksDB 在访问量大时，考察多次连续读和一次读的效率
4. 16：00 - 18：00 2 看brfs的读取流程，修改二期读文件详细设计文档

会议内容
1. 压测，rocksDB 在访问量大时，考察多次连续读和一次读的效率
2. 大小文件写入统一，调整文档，在服务端区分大小文件
3. 数据交换时的数据校验的设计
*** 工作时间：2020.03.10
时间范围：9 : 00 - 18:00
有效工时： 8
工作内容：
1. 9：00 - 10 ：00  1 修改大文件写入流程，统一大小文件，保留原接口
2. 10：00 - 11：00 1 看一期中数据完整性的设计
3. 11：00 - 12：00 1 修改大文件读取流程，调整大文件索引文件的内容
4. 13：00 - 18：00 5 直接下载的rocksdb二进制文件缺少压测工具，在mac和虚拟机上编译了多次rocksdb，完成rocksdb的目录树部分的测试
*** 工作时间：2020.03.11
时间范围：9 : 00 - 18:00
有效工时： 9
工作内容：
1. 9:00 - 10：30 1.5 学习文件系统缓存
2. 10：30 - 12：00 1.5 brfs例会 
3. 13 : 00 - 14 : 00 1 完善大小文件统一写入文档
4. 14：00 - 15：00 1 rocksdb测试，与张奇讨论测试方案，申请堡垒机权限。
5. 15 : 00 - 16 : 30 1.5 测试缓存命中与否对单条read的影响。
6. 16：30 - 17：30 1 申请堡垒机权限，去测试机器上熟悉环境
7. 17：30 - 18：00 0. 5 看db_bench
8. 18 : 00 - 18 : 49 1 zeus会议

会议内容
1. todo: 部署文档、使用手册、应急预案
2. zhucg
   - done: 副本平衡文档
3. zq
   - done: 数据备份的时序图和描述的补充
   - todo: 取消rocksdb远端备份，使用多活，涉及到文档的调整
   - delay: 多个rocksdb同步过程中的读不一致
4. wc
   1. todo ： 接口流程梳理，确定消息格式，大小文件
   2. todo : rocksdb测试
   3. todo : 数据传输demo

5. 
*** 工作时间：2020.03.12
时间范围：9 : 00 - 18:00
有效工时： 8
工作内容：
1. 9:00 - 10:30 1.5 测试，避免get时候加载周围数据到缓存的影响
2. 10:30 - 12:00 1.5 分析测试结果，给出测试报告和方案选择建议
3. 13:00 - 16:00 3 分析hdfs的写入流程中数据传递的消息格式，储备网络知识
4. 16:00 - 16:30 0.5 和俞朋商量具体的消息格式
5. 16:30 - 17:30 1 写网络传输的demo
6. 17:30 - 18:30 1 zeus例会

讨论内容：
1. 数据传递使用界定符还是加显式长度
2. 可以使用rpc么？评估一下
*** 工作时间：2020.03.13
时间范围：9 : 00 - 18:00
有效工时： 8.5
工作内容：
1. 09:00 - 10:00 1 整理文档，参考hdfs的消息传递格式。
2. 10:00 - 13:30 3.5 写文件上传demo，使用简单协议传递消息，当前demo使用的方案性能欠佳，准备看一下rpc的实现
3. 14:00 - 15:00 1 调研几种rpc实现，主要考察易用性和效率
4. 15:00 - 17:30 2.5 画图表示数据结构，开发任务排期
5. 17:30 - 18:00 0.5 zeus会议
*** 工作时间：2020.03.16 
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. 9 : 30 - 10 : 00 0.5 看hdfs dn接收数据的服务
2. 10 : 00 - 12 : 00 2 例会，排期完成
3. 13 : 00 - 14 : 00 1 定义packetHeader，看pb的使用
4. 14 : 00 - 17 : 00 3 数据包封装
5. 17 ：00 - 18 ：30 1.5 数据包单元测试，调整封装代码
6. 18 : 30 - 20 : 00 1.5 和俞朋讨论任务排期，zeus会议

会议内容:
1. 文档汇总
2. 排期
3. 数据包包头里指定文件名
*** 工作时间： [2020-03-17 Tue]
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. 9:30 - 10:00 0.5 看brfs写文件的代码
2. 10:00 - 11:30 1.5 工期评审
3. 11:30 - 12:00 0.5 设计文档调整
4. 13:00 - 14:00 1 继续看brfs写文件regionnode的代码
5. 14:00 - 17:00 3 继续调整设计文档，二期开发中的packet pb定义，和俞朋讨论文档中的问题，目录树搜索评审
6. 17:00 - 18:30 1.5 整合二期文档，调整工期
7. 18:30 - 19:00 0.5 排期和文档调整


todo
1. 目录树去除强依赖
2. 服务端限流
3. 详细设计调整
4. 文件标识
*** 工作时间： [2020-03-18 Wed]
时间范围：9 : 30 - 18:30
有效工时： 9
工作内容：
1. 9:30-10:30 1 看一期的消息定义代码，写封装packet
2. 10:30-12:00 1.5 对照代码和文档，学习pb
3. 13:00-15:00 2 brfs二期开发任务，封装packet
4. 15:00-16:00 1 看brfs的代码
5. 16:00-17:00 1 学习netty http
6. 17:00-19:30 2.5 写文件上传服务，目前封装的包是一个64k左右，由于我的http服务配置，出现了拒绝过大post请求数据的问题，通过修改服务端配置可以正常使用，但接受过大数据有什么影响还要考略一下。brfs目前的配置是65m，远大于packet长度。
*** 工作时间： [2020-03-19 Thu]
时间范围：9 : 00 - 18:00
有效工时： 8
工作内容：
1. 9:30-10:00 0.5 看spark，为例会讨论作准备
2. 10:00-10:23 0.5 进度例会
3. 10:23-12:00 1.5 参考hbase memstore写brfs rn上大文件的累积模块
4. 13:00-17:00 4 梳理brfs一期写入代码
5. 17:00-18:30 1.5 和张奇讨论测试的问题，学习netty，在github上寻找适用于累积模块的缓存方案
*** 工作时间： [2020-03-20 Fri]
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. 9:30 - 11:00 1.5 梳理block pool 逻辑
2. 11:00 - 12:00 1 block pool开发
3. 13:00 - 14:00 1 继续block pool 和block的开发
4. 14:00 - 15:00 1 看代码，data类型替换bytebuffer为byte
5. 15:00 - 16:00 1 reuse block的测试用例
6. 16:00 - 18:30 2.5 看dn的tcp服务代码，写handler
*** 工作时间： [2020-03-23 Mon]
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. 9:30 - 10:00 0.5 文件传输dn服务梳理
2. 10:00 - 10:20 0.3 进度例会
3. 10:20 - 12:00 1.7 熟悉brfs重启的时候，dataengine的中的datapool的保存逻辑。
4. 13:00 - 19:30 6 二期开发，rn收到数据组装成block，写block缓存，调整block pool等
*** 工作时间： <2020-03-24 Tue>
时间范围：9 : 30 - 19:00
有效工时： 8.5
工作内容：
1. 9：30 - 12:00 2.5 二期开发，重构block池和block缓存
2. 13:00 - 14:00 1 继续调整代码
3. 14:00 - 19:00 5 添加log，编写用例，根据测试结果调整代码
*** 工作时间： [2020-03-25 Wed]
时间范围：9 : 30 - 19:50
有效工时： 9
工作内容：
1. 9:30 - 12:00 2.5 整合代码
2. 13:00 - 14:00 1 继续整合代码
3. 14:00 - 19:50 5.5 二期开发，修改代码，提交packet

**** summury
1. idea的依赖报错，下面有红线可能是假的，重启即可消失
2. ssh的config 含义了解
3. git配置多个远程仓库，复习
4. mvn 配置文件和pom配置，mirror配置 含义解读
*** 工作时间： [2020-03-26 Thu]
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. 9:30 - 10:00 0.5 错误文件清理模块的开发
2. 10:00 - 11:00 1 进度例会
3. 11:00 - 12:00 1 继续开发工作
4. 13:00 - 16:00 3 整合代码，梳理handler处理packet逻辑
5. 16:00 - 18:30 2.5 handler单元测试
*** 工作时间： <2020-03-27 Fri>
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. 9:30-10:30 1 修复大文件写入依赖写入顺序的bug
   1. 收到最后一个packet时检查文件数据是否全部收到了
*** 工作时间： [2020-03-30 Mon]
时间范围：9 : 30 - 19:30
有效工时： 9
工作内容：
1. 9:30 - 10:00 0.5 梳理代码，总结问题
2. 10:00 - 11:00 1 进度例会
3. 11:00 - 12:00 1 写入callback 测试
4. 13:00 - 14:00 1 缓冲池写满了的情况
5. 14:00 - 16:00 2 修改驳回请求为等待超时后写入失败
6. 16:00 - 17:00 1 梳理服务客户端的数据交互
7. 17:00 - 19:30 2.5 调整代码，学习guice，添加服务
***** todo
1. 文件写请求拒绝
2. dn 读文件
3. 配置项
4. 写联调
5. netty 的ctx复用
6. writer的mock
****** 服务端客户端端交互
1) 服务端收到来自客户端的post请求，请求中的content 为FSPacket。FSPacket的数据组装方式见对应FSPacketTest.
2) 返回的请求，返回fid时的response内容相同，为fid数组，不同点是fid数组中只有一个fid，即写入文件流的fid
3) 大文件写的过程中间结果的response，我想的3种
   1. 不返回中间结果，只有在文件写完了后才返回fid
   2. 每个packet写入内存都要返回当前seqno
   3. 每个block（1024个packet）写入datanode后，返回最后一个packet的seqno
4) 当服务端blockpool中没有足够的block来工客户端写的时候，驳回客户端写入请求，这里需要客户端能做出相应反应，如停止当前文件的发送
*** 工作时间： [2020-03-31 Tue]
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. 9:30 - 10:30 1 检查代码  提交到gitlab
2. 10:30 - 11:00 0.5 修复block的边界检查
3. 11:00 - 12:00 1 修改申请block逻辑
4. 13:00 - 15:00 2 测试blockpool和block manager，提交代码
5. 15:00 - 16:00 1 学习guice，添加服务
6. 16:00 - 19:00 3 二期开发工作，主要是代码微调，看dn的tcp代码
7. 19:00 - 20:30 1.5 联调，改http响应代码
*** 工作时间： [2020-04-01 Wed]
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. 9:30 - 10:30 1 检查代码
2. 10:30 - 13:00 3 整理代码，添加配置项
3. 14:00 - 15:00 1 看dn的tcp代码，调整二期读取方案
4. 15:00 - 19:30 4.5 学习dn的MappedFileHandler，二期开发，主要是改成filereigon来传输
*** 工作时间： <2020-04-02 Thu>
时间范围：9 : 30 - 21:20
有效工时： 10.5
工作内容：
1. 9:30 - 10:20 0.5 准备会议内容
2. 10:20 - 12:00 2  例会
3. 13:00 - 14:00 1 学guice 调整代码
4. 14:00 - 15:00 1 二期读数据代码，测试
5. 13:00 - 17:00 2 重构代码
6. 17:00 - 21:20 4 部署brfs，客户端和server端联调
 
somthing
1. dn读文件的tcp方式先测一下【建议】
2. dn使用零拷贝方式的文件传输，需要测试
3. 目录树开发和提测 时间冲突
4. todo jax-rs，关注异步写
5. 路由解析 对读的影响
6. promise
7. 性能测试
8. 如何保证同一个文件顺序到达
** 2020-04 April
*** 工作时间： [2020-04-03 Fri]
时间范围：9 : 30 - 22:00
有效工时： 11.5
工作内容：
1. 9:30 - 12:00 2.5 联调测试
2. 13:00 - 14:00 1 二期开发，读文件代码
3. 14:00 - 15:00 1 代码迁移，从原有bootstrap迁到guice管理
4. 15:00 - 17:30 2.5 提测，整合代码
5. 17:30 - 18:30 1 整合读文件代码
6. 18:30 - 22:00 3.5 写文件测试调bug
*** 工作时间： [2020-04-07 Tue]
时间范围：9 : 30 - 19:00
有效工时： 8.5
工作内容：
1. 9:30 - 10:00 0.5 看读写逻辑
2. 10:00 - 11:00 1 修改超时删除逻辑，主要是响应客户端的逻辑
3. 11:00 - 12:00 1 进度例会
4. 13:00 - 16:00 3 学习映射文件和fileregion方式的文件拷贝
5. 16:00 - 19:00 3 dn读取文件的零拷贝方式测试，整合和重构
问题：
1. 文件头
2. 去掉归还block任务
3. 文件更新时间
4. 大文件索引文件格式
*** 工作时间： [2020-04-08 Wed]
时间范围：9:30 - 19:30
有效工时： 9
工作内容：
1. 9:30 - 12:00 2.5 配合测试brfs的文件写入，修改bug
2. 13:00 - 16:30 3.5 开发顺序写入的blockmanager
3. 16:30 - 17:00 0.5 测试blockmanager
4. 17:00 - 18:00 1 排查测试写入时的错误
5. 18:00 - 19:00 1 gui会议
6. 19:00 - 19:37 0.5 学习guice 整理服务代码
*** 工作时间： <2020-04-09 Thu>
时间范围：9 : 30 - 8:20
有效工时： 9.5
工作内容：
1. 9:30 - 11:00 1.5 brfs二期开发，调整log
2. 11:00 - 12:00 1 进度例会
3. 13:00 - 16:30 3.5 fid添加大文件标志位，写入逻辑做相应调整
4. 16:30 - 18:00 1.5 二期开发 目录树相关
5. 18:00 - 20:20 2 学习druid对guice的使用，向张奇学习brfs_rocksdb模块
6. catalog对接rocksdb
todo
1. 批量传packet
2. catalog位置，下载
3. fid 大文件标志位
*** 工作时间： [2020-04-10 Fri]
时间范围：9 : 30 - 22:30
有效工时： 10
工作内容：
1. 9:30 - 10:30 1 写入测试
2. 10:30 - 11:00 0.5 修正代码
3. 11:00 - 12:00 1 实现guice管理下的rocksdb插件依赖的使用
4. 13:00 - 15:00 2 catalog 开发
5. 15:00 - 18:30 3.5 优化blockManager的内存控制
6. 18:30 - 20:30 2 优化写入流程
6. 学习brfs启动框架
问题
1. rocksdb插件化，我怎么使用
*** 工作时间： [2020-04-11 Sat]
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. -Dconfiguration.file=/home/wangchao/IdeaProjects/BRFS/config/server.properties
-Dlogback.configurationFile=/home/wangchao/IdeaProjects/BRFS/config/logback.xml
-Dresource.lib.path=/home/wangchao/IdeaProjects/BRFS/lib
*** 工作时间： [2020-04-13 Mon]
时间范围：9 : 30 - 22:00
有效工时： 12.5
工作内容：
1. 9:30 - 10:30 1 整理问题
2. 10:30 - 12:00 1.5 进度例会
3. 13:00 - 15:30 2.5 改成批量写入
4. 15:30 - 17:30 2 配合测试
5. 17:30 - 22:00 5.5 fix过期删除1.blockcache，2.filewaiting,解决压测bug

问题
1. 写入流程中的异常信息梳理
2. rocksdb
3. 提供gui模拟服务
*** 工作时间： [2020-04-14 Tue]
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. 9:30 - 12:00 2.5 修复内存溢出和超时bug
2. 13:00 - 14:00 1 优化写入日志
3. 14:00 - 16:00 2 插件化后的开发环境配置
4. 16:00 - 19:00 3 提供gui模拟数据
5. 19:00 - 21:00 2 配合测试

写入失败问题
1. de返回null fid
2. 大文件完整性，现在的方式block可能是个空fid，或者写入错误，但是后面的block不知道写错了 
问题
1. 写入方式改成批量写，测试写入的步骤的速度，找出在哪耽误时间了
2. 目录树开发+gui 读写统计开发
*** 工作时间： [2020-04-15 Wed]
时间范围：9 : 30 - 22:00
有效工时： 11.5
工作内容：
1. 9:30 - 10:30 1 catalog开发
2. 10：30 -12:00 2.5 处理写入时dtaconsumer interrupted问题
3. 13：00 - 14：00 1 clear file 的时候释放写入资源
4. 14：00 - 16：00 2 fix 超时时间误判的bug
5. 16：00 - 22：00 6 catalog插件化，配置写入参数，配合压测 
*** 工作时间： [2020-04-16 Thu]
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. 9:30 - 10:30 1 catalog 插件开发
2. 10:30 - 12:00 1.5 例会
3. 13:00 - 15:00 catalog自测
*** 工作时间： [2020-04-17 Fri]
时间范围：9 : 30 - 19:00
有效工时： 8.5
工作内容：
1. rocskdb 接入brfs，自测，修改bug
2. 写入和读取测试
** 工作时间：[2020-06-22 Mon]
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. 会议讨论大小文件同时写的内存溢出问题
** 工作时间： [2020-07-02 Thu]
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. 学习rocksdb调优
2. 学习kafka的设计
3. 例会
4. 排查regionnode启动错误的问题
** 工作计划
1. druid
2. presto
3. todo整合，查询任务分配
4. 目前，dpl1.0——》dpl2.0 测试
5. 第一步。先熟悉1和2的语法定义

** TODO check point 
1) [X]FileRegion方式读文件
3) [X] 积累模块，按sn，按filename，按偏移量
4) 可管理，看大小，支持同时写大文件的数量限制
5) [X]hbase用跳表加快写入和查找速度，brfs使用阻塞队列packetq来存一个文件的packet
6) storageName+filename=filekey
7) onConstruction（filekey => file）,file中持有队列
8) [X]delay 一个缓存池，重复使用,应该不需要，因为创建不频繁
9) [X]同一个handler实例 的数据共享
10) [X]数据结束标志
* 项目
** brfs
*** 项目优势
1. 多个小文件填满一个文件块
*** 大文件
**** 流程
**** 接口
***** client
1. BRFilesystem#createFile(path); //创建大文件 返回outPutStream
2. BRFilesystem#createDirectory(path); //创建路径，返回key（父id+DirName）
***** server
1. 
**** 写入时序图
#+BEGIN_SRC plantuml :file /Users/wangchao/iosdev/cheepsheets/resource/img/brfs-big-file-write-2.png :cmdline -charset utf-8
  @startuml
  !include ../../puml/sequence-style.puml
  title 大文件写入时序图
  participant Client as c
  participant RegionNode as rn
  participant RocksDB as rd
  participant DataEngine as de

c -> rn  ++: 建立连接 向rn发送数据报 每个数据包中有文件标识和偏移量
rn -> rn : 按文件名积累文件数据 记录大小
group 大文件
loop 将数据全部写入DataNode
rn -> de ++: 将文件block数据用DataEngine落盘
de --> rn : RegionNode将记录key=>(pos=>fid)
deactivate de
End
rn -> de : 将所有fid和对应偏移量写入到datanode
de --> rn : 返回一个大文件fid
end
group 小文件
rn -> de ++: 小文件落盘
de --> rn : 返回fid
end
group 支持自定义文件名时
rn -> rd ++: 将fid按文件名写入RocksDB
rd --> rn : 返回entry
deactivate rd
end
rn --> c : 返回文件fid
  @enduml
#+END_SRC

#+RESULTS:
[[file:/Users/wangchao/iosdev/cheepsheets/resource/img/brfs-big-file-write-2.png]]
**** 读取时序图
#+BEGIN_SRC plantuml :file /Users/wangchao/iosdev/cheepsheets/resource/img/brfs-big-file-read-1.png :cmdline -charset utf-8
@startuml
!include ../../puml/sequence-style.puml
title 大文件读取时序图
participant Client as c
  participant RegionNode as rn
  participant RocksDB as rd
  participant DataEngine as de
c -> rn ++: read by path
rn -> rd ++: get fid by path
rd --> rn : fid
deactivate rd
rn --> c : 文件fid
c -> de ++: 按fid读取文件 
de --> c : 返回索引文件 在这分辨大小文件
deactivate de
group 大文件
loop 读取fids
c -> de ++: 按偏移量拿到对应服务的连接读取fid对应的block文件
de --> c : 文件数据
c -> c :写入数据流 异步
deactivate de
end
end
group 小文件
c -> c :直接组装个流
end

c -> c: 从流中读
@enduml
#+END_SRC

#+RESULTS:
[[file:/Users/wangchao/iosdev/cheepsheets/resource/img/brfs-big-file-read-1.png]]
**** 数据格式
*** 目录树
已知：
1. rocksDB是一个KV存储引擎
问：如何将一颗树压扁存如KV结构中？
**** 设计方案
1. 目录中每一节点，不论是文件夹还是文件，视作一条记录存储在rocksDB中。
2. 每条记录的key由当前节点的父id和当前节点文件名组成。
3. 每条记录的value由当前节点id和brfs的fid组成
**** 接口
***** BRFilesystem#list(String path)
列出path指定的列表信息
1. path为目录时，返回目录下inode列表。
2. path为文件时，返回列表中只有当前文件inode
#+BEGIN_SRC plantuml :file /Users/wangchao/iosdev/cheepsheets/resource/img/brfs-listPath.png :cmdline -charset utf-8
  @startuml
  !include ../../puml/sequence-style.puml
  title list时序图
  participant Client as c
  participant RegionNode as rn
  participant RocksDB as rd
  c -> rn ++:list(path)
  activate c
  group util path 到最后一项
          rn -> rd ++:get(path)
          rd --> rn: list of entry
end
  deactivate rd
  rn -> rn : 用entries组织list of inode
  rn --> c:response
  deactivate rn
  deactivate c
  @enduml
#+END_SRC

#+RESULTS:
[[file:/Users/wangchao/iosdev/cheepsheets/resource/img/brfs-listPath.png]]

***** BRFilesystem#copyToLocal(String src，dst)
从文件系统中下载src文件到dst
#+BEGIN_SRC plantuml :file /Users/wangchao/iosdev/cheepsheets/resource/img/brfs-copyFileToLocal.png :cmdline -charset utf-8
  @startuml
  !include ../../puml/sequence-style.puml
  title copyToLocal 时序图
  participant Client as c
  participant RegionNode as rn
  participant RocksDB as rd
  participant DataNode as dn
  c -> rn ++:copyToLocal(path，dst)
  activate c
  == list 阶段开始 ==
          rn -> rd ++:查询
          rd --> rn: list of entry
  deactivate rd
  rn --> c:response with fid
  deactivate rn
  == list 阶段结束 ==
  c -> c : confirm
  c -> dn ++: copyToLocal(fid)
  dn -> c : return 数据流
  deactivate dn
  c -> c :从数据流中读数据写入到dst
  deactivate c
  @enduml
#+END_SRC

#+RESULTS:
[[file:/Users/wangchao/iosdev/cheepsheets/resource/img/brfs-copyFileToLocal.png]]

**** 读写示例
/                                                               key      :   value
├── home                                                 1home  :   2
│      ├── user1                                       2user1  :   3
│               ├──file1                                
│      ├── user2                                       2user2  :   4
│      ├── user3                                       2user3  :   5
                                                                 3file1   :   fid
1. 读 read /home/user1/file1 
   1. get(1home) => 2
   2. get(2user1) => 3
   3. get(3file1) => fid
2. 显示目录内容 read /home
   1. get(1home) =>2
   2. getByPrefix(2) => kvs[2user1=>3 , 2user2=>4 , 2user3=>5]

3. 写目录 create /home/user3
   1. get(1home) => 2
   2. put(2user3,5)
4. 写文件 create /home/user1/file1
   1. get(1home) => 2
   2. get(2user1) => 3
   3. put(3file1,fid)

**** 接口描述
1. 对于创建文件操作，比如想创建/home/work/目录，则首先在/目录中查找home目录，由于/的EntryID为1，所以第一次查找时，key为1home，然后读出其value，解析后发现/home的EntryID为2，则将此EntryID记下，继续往下走，发现work即为所需要创建的文件，则为其申请一个EntryID（假设为9），此时，写入一条记录，按照上面的规则，其key为2work，value为work创建的时间等信息，以及work的EntryID（9）
2. 对于删除操作，比如把刚刚创建的/home/work目录删除，只需要将key为2work的这条记录删除即可
3. 对于读取操作，比如想读取/home/dirx/filex文件中的内容，则首先读取1home这条key所对应的value，解析发现value中记录的EntryID为2，然后再去读取2dirx这条key所对应的value，解析发现value中记录的EntryID为4，然后再去读取4filex这条key所对应的value，从里面解析出/home/dirx/filex的实际数据存放位置，进行文件内容的读取
4. 对于List目录操作，比如想看看根目录下有哪些文件和目录，由于每个文件和目录在存储时，其key中都包含父目录的EntryID，因此，只需进行一次扫描即可。比如ls /，则只需扫描leveldb中，以1\0x0为前缀的key即可，当遇到2时停止，所得结果即为/目录下的所有内容
5. 对于Rename操作，只需要改动其key即可。比如想要把/home/diry/filey文件移动到home/dirx目录中，按照之前的规则，/home/diry/filey在leveldb中存储的key为5filey，/home/dirx的EntryID为4，把5filey这条记录中的内存读取出来，以4filey为key，再次存储到leveldbk ，然后将5filey这条记录删除，即完成了Rename操作
*** 数据完整性
brfs在传输过程中，没有进行校验，只有dn落盘和读取的时候才会涉及数据校验
*** 排期
**** 文件传输
***** 协议
SCHEDULED: <2020-03-16 Mon> DEADLINE: <2020-03-18 Wed>
1. 实现具体协议
***** 客户端
1. write
2. read
DEADLINE: <2020-03-25 Wed> SCHEDULED: <2020-03-19 Thu>
***** 服务器
1. write
2. read
DEADLINE: <2020-04-03 Fri> SCHEDULED: <2020-03-26 Thu>
**** 目录树
***** 提供接口
DEADLINE: <2020-03-20 Fri> SCHEDULED: <2020-03-16 Mon>

***** 具体实现
DEADLINE: <2020-04-08 Wed> SCHEDULED: <2020-04-06 Mon>

***** test[2020-03-16 Mon]

工作时间：'(file-name-nondirectory buffer-file-name)'
时间范围：9 : 00 - 18:00
有效工时： 8
工作内容：
1. 
* 环境

** rocks测试环境
1. ssh -p 2226 root@192.168.101.88

** gitlab地址
[[http://192.168.106.38/wangchao/BRFS/activity][gitlab]]
** 跳板机

1. 地址  ssh -i /Users/wangchao/tools/wangchao.pem -p 2226 wangchao@ 118.194.54.253
2. 按选项进入有权限的机器，这里进入10.240.67.231
* somthing test
#+begin_src emacs-lisp :tangle yes
(use-package esup
  :ensure t
  ;; To use MELPA Stable use ":pin mepla-stable",
  :pin melpa
  :commands (esup))
#+end_src
** TODO gtd  :brfs big file:
- State "TODO"       from              [2020-03-14 Sat 16:10]
*** TODO task1
*** TODO task2
*** TODO task3
工作时间： [2020-06-16 Tue]
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. XSxc

** 工作时间： [2020-06-18 Thu]
时间范围：9 : 30 - 24:00
有效工时： 12
工作内容：
1. 排查大小文件写入时小文件写入慢的问题
2. 排查rocksdb同步时候丢失连接的问题
3. 与张奇讨论rocksdb批量同步的实现方案
4. 排查小文件写入过程中流量间歇性降低的问题

todo
继续排查流量不稳疑似卡住的问题
** 工作时间： <2020-06-18 Thu>
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. 
1. 排查日志报错昨天晚上
   1. response error 是超时丢弃的
   2. 没有可用的磁盘节点是在00：19时重启时发生的正常
2. 卡住 加日志，排查jstack
   1. 应该不是datanode响应不及时，因为流量高的时候也是waiting占大多
3. 队列代码回退
4. 流量不稳，这个应该是fetch机制的事，以前就有
5. datanode内存泄漏
6. 为什么会影响小文件的tps
** 工作时间： [2020-06-19 Fri]
时间范围：9 : 30 - 18:30
有效工时： 8
工作内容：
1. 
** 周报
1. 排查rocksdb同步时候丢失连接的问题
2. 排查小文件写入过程中流量间歇性降低的问题,暂时确定是fetch机制的问题
3. 排查大小文件同时写datanode内存泄漏的问题
4. 调整datanode写入队列,添加exceptionCaught日志
