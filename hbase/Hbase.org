* Hbase
** 概念
1. 什么是Hbase?
   1. Google Bigtable的开源实现
   2. 分布式数据库
   3. 列式存储
   4. NoSql
2. 列式存储的优势
   1. 行中没有保存数据的列不占空间
3. Hbase为什么高效？
   1. 将随机读写转换为顺序读写，适合高并发写入
   2. 均衡效果好，读写性能与机器数线性相关
   3. 空间高效利用，行中没有保存数据的列不占空间，Hbase存储更为紧凑
** Hbase使用
*** 适用场景
- 列族结构经常调整
- 结构化数据或半结构化数据
- 需要高并发写入

*** 不适用场景 
- 需要事务 因为hbase只有行锁级别的事务
- 需要关系计算，例如 join,union,groupby，因为是列存
- 不按rowkey查询
- 高并发随机读

*** hbase shell
- 常用工具
  - 状态查询
  - ddl dml
  - 集群工具
  - replication
  - 快照
  - namespace
*** 常用列族属性
- IN_MEMORY : 在缓存中的优先级，常驻内存
*** thrift
- 跨语言的开发
*** 协处理器
**** 两类协处理器
1. observe
   - 类似触发器或回调函数
   - 在某一事件后触发
2. endpoint
   - 类似存储过程
   - 通过rpc调用rs端的计算
**** 协处理器的配置
- 全局 : jar包上传到服务端，并配置
- 用户表协处理器 : hbase shell 或api部署
- 一个参数 :避免因协处理器的异常导致rs的宕机，禁用有问题的协处理器
**** 经验
- 用处
  - 辅助监控 observer
  - 协助处理数据-索引表
  - 统计操作
    - 各region分别统计
    - 客户端归并
- 误区
  - endpoint的数据太大
  - 没有对资源占用进行估计
    - 使用过多线程 cpu
    - 使用过多内存 rs oom
** Hbase基本架构
- 客户端
- master
- regionserver
- zk
- hdfs 
** 运维
*** 集群状态信息
- web页面
- log查看
  - 是否有Exception
  - 是否有线程意外退出，exit关键字
- gclog
  - gc时间长或者full gc比较多，那么内存不够用或者配置有问题
- hbase监控痛点
  1. 组件下线
  2. unassigned region时间过长
     - zkdump或zk中获取:unassignedregion文件中有内容且超过一定时间
       - 要么有严重的容灾
       - 要么容灾卡住了
  3. regionserver处理客户端请求的时间过长
     - 某系关键线程可能卡住了
  4. storefile总数过多
     1. too many open file 异常
     2. 影响其他线程
     3. 也说明compaction线程不太行
- 工具hbck查看
  - 检测和修复数据不一致，表信息，rs挂载，hdfs目录这三类信息
  - -repair 启动所有修补项
  - 修复前确认没有正在跑的task，避免家中现有问题
  - hbck是异步的，修复后根据受影响的region数量等待一段时间，再次检测
*** 数据迁移和备份
**** 迁库需求
1. 服务器迁机房
2. 服务扩容至更大的集群
3. 集群版本升级
4. 从传统数据库导入
5. 备份
**** bulkload
**** distcp
1. hdfs 集群间的拷贝
2. 拷贝完，(0.94后)用一次hbck修复数据不一致来加载表(旧版本用addTable.rb)
**** export+import
**** copytable
- 逐条put
**** 实时备份 replication
** inbox
- 分区容忍性 : 系统中任意信息的丢失或者失败不影响整个系统的运作
  - 例如 : 一个rs挂掉了或者一个dn挂掉了，对整个系统的影响是很小的
- zk协调rs的容灾问题
- hbase releasenodes
- hbase_cleanup.sh zk有一致性问题的时候用来删除zk上的数据，有什么弊端么
- hbase 与hdfs append
- 前缀树
- 压缩算法的比较，与数据特性的关系
- bloomfilter什么时候用rowcol
- hbase 计数器
- 底层数据迁移时 版本不正确 使用bin/hbase migrate'
- 使用hfile命令行工具可以查看hfile中key所占的空间比
** protobuf
*** 一些protobuf相关的信息
+ 从protobuf .proto文件生成java文件是构建的一部分
+ proto文件在2.0以后被集中起来
+ hbase2.0以后 proto的使用变得有点复杂，为了升级到protobuf3来配合netty的零拷贝。hbase core的protobuf从HDFS独立出来。
+ 相比hbase-protocol，hbase core已经开始依赖hbase-protocol-shaded了，但是为了兼顾endpoint，还保留着hbase-protocol。以后会理清吧
*** hbase项目生成protos的java文件
1. build protocol-shaded子模块,有需要还会buildprotocol模块
#+BEGIN_SRC sh
  # pl 指定打包的模块，可以用路径也可以用坐标，如果父项目同时是父目录，那么进入父目录下，直接“-pl 项目目录名”即可
  # -am：意味着also-make （dependency），即同时打包依赖的模块；
  mvn clean install -pl hbase-protocol-shaded -am
#+END_SRC
2. 刷新maven index，找到生成的代码

** Mini-clushter

** WAL
通常，一个region上的所有table公用一个wal。但是hbase：meta有自己的专用wal
*** purpose 
用来恢复在rs宕机时还没来的及flush的memstore中的变化的数据
*** 在hdfs上的位置
+ /hbase/WALs/{每个region}
+ 暂时不要使用hadoop ec目录

*** 配置
+ hbase.wal.provider ：具体的wal实现
+ hbase.wal.meta_provider ： meta表专有的实现
*** wal Provider
**** 具体的
1. asyncfs ：基于非阻塞的dfsClient实现的wal写入器，目前重度依赖hdfs的更新，会在失败时替换会filesystem
2. filesystem ：基于老式的阻塞dfsClient
3. multiwal ： 一个rs上多个wal
*** wal splitting
当一个region open时，需要把wal中属于该region的edit 重放，因此edit需要按region分组，这个分组过程就是log splitting
**** 触发时机，master是执行者
1. start-up
2. serverShutdownHandler
**** procedure
1. The /hbase/WALs/<host>,<port>,<startcode> directory is renamed.
2. 按region分组，一个分组一个分组的读，写入到/hbase/<table_name>/<region_id>/recovered.edits/.temp，写完后.temp 重命名为该文件中的第一条log的sequence id，sequenc id用来决定replay时从哪开始
3. 分组完成后，assign region ，region open 后replay，然后flush，然后删除recovered.edits
**** 2.0以后不需要使用PV2代替zk做协调
*** wal Compression

** Region

** master
*** 职责
1. monitor所有rs
2. 保存所有metadata
*** HMasterInterface
面向metadata的方法
+ Table (createTable, modifyTable, removeTable, enable, disable)
+ ColumnFamily (addColumn, modifyColumn, removeColumn)
+ Region (move, assign, unassign)
*** 线程
**** 1. LoadBalancer

**** 2. CatalogJanitor
周期性的检查清理hbase:meta

*** MasterProcWAL
master上procedure的wal

** regionServer

*** HRegionRegionInterface
面向data和region管理
+ Data (get, put, delete, next, etc.)
+ region（master下发命令的执行者）

*** 线程
1. CompactSplitThread ： for split and minor compaction
2. MajorCompactionChecker
3. MemStoreFlusher
4. LogRoller

*** block cache
hbase提供两种不同的cache来缓存从hdfs读上来的数据块
1. on-heap LruBlockCache
2. BucketCache 通常在堆外

**** CombinedBlockCache
一个管理类，开启bucketCache，形成一个双层缓存，L2（bucketcache）在堆外缓存datablock，L1(LruBlockCache)缓存metaBlock（index block和bloom block）
**** LruBlockCache
***** 设计：内部为block划分3个优先级
1. Single access priority 初次从hdfs load上来的
2. Multi access priority 在1中再次命中的
3. In-memory 配置的常驻内存，例如meta表
***** 使用
+ 集群中总cache大小的计算：rs数 * heap size * hfile.block.cache.size * 0.99
+ hfile.block.cache.size 默认0.4
+ 0.99 lru装载因子，超过这个比例，就淘汰block
+ 频繁的eviction将会导致更多的GC
+ map一个table的时候可以选择不带blockcache的scan
**** 堆外缓存
1. 2.0以前，使用堆外缓存意味着在读取的时候先要把block从堆外copy回来，尽管避开了GC，但是速度慢了
2. 2.0以后，改变了读路径，可以直接读非堆上的block，零拷贝的读。同时又兼具自己管理GC的好处，从HBase 2.0.0起，L1和L2的概念已被弃用。当BucketCache打开时，DATA块将始终转到BucketCache，而INDEX / BLOOM块将转到堆LRUBlockCache。 cacheDataInL1支持已被删除
**** bucketBlockCache
三种模式
+ off-heap
+ file
+ mmaped file mode

** off-heap


** quota
*** 配置
+ hbase.quota.enabled 是否启用quota
+ hbase.quota.refresh.period 配置刷新周期
+ 可以提前配额或者在runtime配额

*** 基本使用
#+BEGIN_SRC sh
  # Limit user u1 to 10 requests per second
  hbase> set_quota TYPE => THROTTLE, USER => 'u1', LIMIT => '10req/sec'

  # Limit user u1 to 10 read requests per second
  hbase> set_quota TYPE => THROTTLE, THROTTLE_TYPE => READ, USER => 'u1', LIMIT => '10req/sec'

  # Limit user u1 to 10 M per day everywhere
  hbase> set_quota TYPE => THROTTLE, USER => 'u1', LIMIT => '10M/day'

  # Limit user u1 to 10 M write size per sec
  hbase> set_quota TYPE => THROTTLE, THROTTLE_TYPE => WRITE, USER => 'u1', LIMIT => '10M/sec'

  # Limit user u1 to 5k per minute on table t2
  hbase> set_quota TYPE => THROTTLE, USER => 'u1', TABLE => 't2', LIMIT => '5K/min'


  # Limit user u1 to 10 read requests per sec on table t2
  hbase> set_quota TYPE => THROTTLE, THROTTLE_TYPE => READ, USER => 'u1', TABLE => 't2', LIMIT => '10req/sec'

  # Remove an existing limit from user u1 on namespace ns2
  hbase> set_quota TYPE => THROTTLE, USER => 'u1', NAMESPACE => 'ns2', LIMIT => NONE

  # Limit all users to 10 requests per hour on namespace ns1
  hbase> set_quota TYPE => THROTTLE, NAMESPACE => 'ns1', LIMIT => '10req/hour'

  # Limit all users to 10 T per hour on table t1
  hbase> set_quota TYPE => THROTTLE, TABLE => 't1', LIMIT => '10T/hour'

  # Remove all existing limits from user u1
  hbase> set_quota TYPE => THROTTLE, USER => 'u1', LIMIT => NONE

  # List all quotas for user u1 in namespace ns2
  hbase> list_quotas USER => ‘u1, NAMESPACE => 'ns2'

  # List all quotas for namespace ns2
  hbase> list_quotas NAMESPACE => 'ns2'

  # List all quotas for table t1
  hbase> list_quotas TABLE => 't1'

  # list all quotas
  hbase> list_quotas
#+END_SRC
*** 全局配置同时配置某个用户不生效
#+BEGIN_SRC sh
  # a per-namespace request limit
  hbase> set_quota NAMESPACE => 'ns1', LIMIT => '100req/min' 

  # user u1 is not affected by the limit
  hbase> set_quota USER => 'u1', GLOBAL_BYPASS => true


#+END_SRC
*** 配置Namespace Quotas : 
  + hbase.namespace.quota.maxtables  配置一个namespace里最多可以有多少个table
  #+BEGIN_SRC sh
    # Create a namespace with a max of 5 tables
    hbase> create_namespace 'ns1', {'hbase.namespace.quota.maxtables'=>'5'}

    # Alter an existing namespace to have a max of 8 tables
    hbase> alter_namespace 'ns2', {METHOD => 'set', 'hbase.namespace.quota.maxtables'=>'8'}

    # Show quota information for a namespace
    hbase> describe_namespace 'ns2'

    # Alter an existing namespace to remove a quota
    hbase> alter_namespace 'ns2', {METHOD => 'unset', NAME=>'hbase.namespace.quota.maxtables'}
  #+END_SRC
  + 也可以配置一个ns上有多少个region
    #+BEGIN_SRC sh
      # Create a namespace with a max of 10 regions
      hbase> create_namespace 'ns1', {'hbase.namespace.quota.maxregions'=>'10'}

      # Show quota information for a namespace
      hbase> describe_namespace 'ns1'

      # Alter an existing namespace to have a max of 20 regions
      hbase> alter_namespace 'ns2', {METHOD => 'set', 'hbase.namespace.quota.maxregions'=>'20'}

      # Alter an existing namespace to remove a quota
      hbase> alter_namespace 'ns2', {METHOD => 'unset', NAME=> 'hbase.namespace.quota.maxregions'}
    #+END_SRC
*** Space Quotas
+ 限制hbase的ns 和 table可以使用多少文件系统的存储
*** 待续。。。
* Hbase源码
** Hbase-RPC 
- 远程过程调用
** memstore
*** 一个图
#+BEGIN_SRC plantuml :file /Users/wangchao/iosdev/cheepsheets/resource/img/hbase-memstore-seq.png :cmdline -charset utf-8
  @startuml
  participant HStore as store
  participant memstore as mem

  store ->  mem ++: 使用反射，读取配置中的memstorelist生成memstore对象 
  @enduml
#+END_SRC

#+RESULTS:
[[file:/Users/wangchao/iosdev/cheepsheets/resource/img/hbase-memstore-seq.png]]
** inbox
1. 
* test
#+begin_src plantuml :file tryout.png
  Alice -> Bob: synchronous call
  Alice -> Bob: asynchronous call
#+end_src

#+RESULTS:
[[file:tryout.png]]
