#+title: ozone
* create key
** RpcClient
1. 校验，非空检查
2. 构造OmKeyArgs
3. 随机一个request uuid
4. 使用 OzoneManagerProtocol 打开一个OpenKeySession
5. createOutputStream(session)

* ReplicationManager

** 维护一个container的replica正确的冗余
只有container关闭的，我们才会对其replica进行维护
*** 先整理container，能关闭则关闭，关闭操作就是本次处理该container的唯一操作
1. scm上的container状态是open的，汇报上来的container处于这几种状态则关闭(更改scm上container的状态为CLOSING，向所有副本发送关闭命令)
   - 副本不是open的
   - 副本个数不对
   - 副本分布不对
2. scm上的container状态是CLOSING的，直接向所有副本发送关闭命令
3. scm上的container状态是QUASI_CLOSED,并且汇报上来的一半以上的非同源副本都准备好了关闭
*** 整理正在执行命令的副本的状态
把完成的或超时的命令从inflight集合中去掉
1. inflightRelication： 这是用来追踪副本增加命令的
2. inflightDeletion：这是用来追踪副本删除命令的
*** 开始检查副本，增删以保证正确冗余
1. container状态至少为CLOSED，且副本状态一致，视为健康，不做处理
2. 检查是否需要补充副本,两种状态需要补充
   1. 不符合防止策略
   2. 副本数少于冗余因子
3. 检查是否需要删除副本，1种状态可能需要删除
   1. 副本过剩

*** 如何补充副本？
分3部分
**** 1. 选择模版副本列表
状态为CLOSED和QUASI_CLOSED状态，且没有正在执行删除副本命令的副本所在dn，组成模版副本dn列表

**** 2. 选择增加副本的dn节点
排除已经持有该container和正在补充该container的dn

**** 3. 向选出来的dn发送副本增加命令
1. 只有在副本数量缺失，或者按1-2的补充计划后，副本的分布能够得到改善的时候，才会真正的发送命令
2. 发送了副本补充命令后在需要使用inflightReplication追踪该命令

*** 如何删除副本？

**** 选择需要删除的副本
1. 不能被删除的：每个同源(拥有相同的originID)的副本至少要保留一个
2. 需要被删除的
   1. 状态与container状态不一致的，如果此时副本数是过剩的，直接发送删除副本命令
   2. 删除原则：副本过剩的时候，如果已经是不正确的副本分布或者删除一个replica并不能使原本正确的分布变得不正确，总之就是删除一个副本不会使分布变得更坏



** container的状态转换
*** 引起container的状态转换事件
**** 1. CLOSE_CONTAINER事件
***** 触发close的事件的情况如下
- node failure
- volume failure
- volume out of space
- node out of space
***** close事件的主要逻辑
1. 改变scm上的container状态为CLOSING
2. 通知所有该container所在的dn转换该container为CLOSING

* scrub
负责数据的清理工作，当数据损坏时，及时的触发container-replication任务

** 数据检查

*** 元数据检查

**** 必要准备
1. container controller
2. 可配的检查周期

*** 数据检查
按volume划分检查任务

** 限流实现


** 磁盘管理

*** 磁盘检查

*** 磁盘选择

** container状态，不同于container-replica的状态

* 副本均衡

* 源码
** 前置配置
- 1. 可以在命令行或者启动脚本中配置ozone的配置文件
#+begin_src sh
[process of ozone] -conf xxx/ozone-default.xml
#+end_src


- 2. 在配置中规划好了所有进程的数据目录,可以降级到同一个目录下(方便配置,测试用)
  #+begin_src xml
    <property>
        <name>ozone.metadata.dirs</name>
        <value>rootdir/ozone/metaDir</value>
        <tag>OZONE, OM, SCM, CONTAINER, STORAGE, REQUIRED</tag>
        <description>
          This setting is the fallback location for SCM, OM, Recon and DataNodes
          to store their metadata. This setting may be used only in test/PoC
          clusters to simplify configuration.

          For production clusters or any time you care about performance, it is
          recommended that ozone.om.db.dirs, ozone.scm.db.dirs and
          dfs.container.ratis.datanode.storage.dir be configured separately.
        </description>
      </property>

  #+end_src
** SCM
*** init
在配置的scm.db.dirs中生成集群版本信息,生成scm节点的id信息
#+begin_src shell
  ozone scm --init

  #SCM initialization succeeded. Current cluster id for sd=/rootdir/ozone/metaDir/scm;cid=CID-efcf1bf1-a78b-4d9d-a99d-d80ecb768602;layoutVersion=0

  tree pathOfSCM

  #scm
  #└── current
  #    └── VERSION

  cat metaDir/scm/current/VERSION

  #Thu Oct 14 17:36:38 CST 2021
  nodeType=SCM
  scmUuid=043d1151-14a4-4e76-a667-267a24e3b99f
  clusterID=CID-efcf1bf1-a78b-4d9d-a99d-d80ecb768602
  cTime=1634204198060
  layoutVersion=0
#+end_src

*** ozone scm
启动scm

**** (optional)启动scm的web服务
相关配置
#+begin_src xml
    <property>
      <name>ozone.scm.http-address</name>
      <value>0.0.0.0:9876</value>
      <tag>OZONE, MANAGEMENT</tag>
      <description>
        The address and the base port where the SCM web ui will listen on.

        If the port is 0 then the server will start on a free port.
      </description>
    </property>
    <property>
      <name>ozone.scm.http-bind-host</name>
      <value>0.0.0.0</value>
      <tag>OZONE, MANAGEMENT</tag>
      <description>
        The actual address the SCM web server will bind to. If this
        optional address is set, it overrides only the hostname portion of
        ozone.scm.http-address.
      </description>
    </property>
    <property>
      <name>ozone.scm.http.enabled</name>
      <value>true</value>
      <tag>OZONE, MANAGEMENT</tag>
      <description>
        Property to enable or disable SCM web ui.
      </description>
    </property>
    <property>
      <name>ozone.scm.https-address</name>
      <value>0.0.0.0:9877</value>
      <tag>OZONE, MANAGEMENT</tag>
      <description>
        The address and the base port where the SCM web UI will listen
        on using HTTPS.

        If the port is 0 then the server will start on a free port.
      </description>
    </property>
    <property>
      <name>ozone.scm.https-bind-host</name>
      <value>0.0.0.0</value>
      <tag>OZONE, MANAGEMENT</tag>
      <description>
        The actual address the SCM web server will bind to using HTTPS.
        If this optional address is set, it overrides only the hostname portion of
        ozone.scm.https-address.
      </description>
    </property>

#+end_src

***** TODO scm web 页面 可以获得的信息

**** 启动后scm目录下的文件结构
#+begin_src sh
  metaDir
  ├── db.checkpoints
  ├── scm
  │   └── current
  │       └── VERSION
  └── scm.db  //用rokcsdb来作为scm的持久化存储
      ├── 000024.log
      ├── CURRENT
      ├── IDENTITY
      ├── LOCK
      ├── LOG
      ├── LOG.old.1634205202869713
      ├── LOG.old.1634205228566554
      ├── LOG.old.1634205442027664
      ├── LOG.old.1634205709142623
      ├── MANIFEST-000023
      ├── OPTIONS-000023
      └── OPTIONS-000026

#+end_src

**** 启动不同的服务
对不同的protocol,在不同的端口上启动不同的服务,在log中记录
#+begin_src text
	todo : 可以看这几个protocol面向的场景
  INFO   StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
  INFO   ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
  INFO   ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
#+end_src

** ozone datanode

*** 配置存储目录
不配置会在/tmp目录下生成临时文件
#+begin_src xml
  <property>
      <name>hdds.datanode.dir</name>
      <value>/xxx/ozone/volumes</value>
      <tag>OZONE, CONTAINER, STORAGE, MANAGEMENT</tag>
      <description>Determines where on the local filesystem HDDS data will be
        stored. Defaults to dfs.datanode.data.dir if not specified.
        The directories should be tagged with corresponding storage types
        ([SSD]/[DISK]/[ARCHIVE]/[RAM_DISK]) for storage policies. The default
        storage type will be DISK if the directory does not have a storage type
        tagged explicitly.
      </description>
  </property>

#+end_src

目录结构
#+begin_src shell
  tree path
  #── volumes
  #    ├── hdds
  #    └── scmUsed


  cat scmUsed

  #8192 1634210195271% 
#+end_src

*** container存储结构
#+begin_src text
  └── volumes
      ├── hdds
      │   ├── 043d1151-14a4-4e76-a667-267a24e3b99f
      │   │   └── current
      │   │       └── containerDir0
      │   │           ├── 3
      │   │           │   ├── chunks
      │   │           │   │   ├── 107104110352138242.block
      │   │           │   │   ├── 107104143830548485.block
      │   │           │   │   ├── 107104264322678795.block
      │   │           │   │   ├── 107104346305069070.block
      │   │           │   │   ├── 107104351582093329.block
      │   │           │   │   ├── 107104370581897236.block
      │   │           │   │   └── 107104376491409431.block
      │   │           │   └── metadata
      │   │           │       ├── 3.container
      │   │           │       └── 3-dn-container.db
      │   │           │           ├── 000004.sst
      │   │           │           ├── 000006.log
      │   │           │           ├── CURRENT
      │   │           │           ├── IDENTITY
      │   │           │           ├── LOCK
      │   │           │           ├── LOG
      │   │           │           ├── LOG.old.1634282567964969
      │   │           │           ├── MANIFEST-000005
      │   │           │           ├── OPTIONS-000005
      │   │           │           └── OPTIONS-000008
#+end_src

*** 使用rocksdb作为元数据存储,每个元数据一个库
每个container的元数据存储在自己的rocksdb中

**** 使用jmx获得每个container中rocksdb的统计信息
1. 将ozone.metastore.rocksdb.statistics打开,这会带来5%-10%的性能损耗
   #+begin_src xml
     <property>
         <name>ozone.metastore.rocksdb.statistics</name>
         <value>ALL</value>
         <tag>OZONE, OM, SCM, STORAGE, PERFORMANCE</tag>
         <description>
           The statistics level of the rocksdb store. If you use any value from
           org.rocksdb.StatsLevel (eg. ALL or EXCEPT_DETAILED_TIMERS), the rocksdb
           statistics will be exposed over JMX bean with the choosed setting. Set
           it to OFF to not initialize rocksdb statistics at all. Please note that
           collection of statistics could have 5-10% performance penalty.
           Check the rocksdb documentation for more details.
         </description>
       </property>

   #+end_src
2. 在datanode启动的server端口上使用jmx命令
   #+begin_src text
     http://localhost:9882/jmx

     # 获得如下信息
     {
         "name" : "Hadoop:service=Ozone,name=RocksDbStore,dbName=5-dn-container.db",
         "modelerType" : "",
         "BLOCK_CACHE_MISS" : 6,
         "BLOCK_CACHE_HIT" : 29,
         "BLOCK_CACHE_ADD" : 6,
         "BLOCK_CACHE_ADD_FAILURES" : 0,
         ....
     },
     {
         "name" : "Hadoop:service=Ozone,name=RocksDbStore,dbName=4-dn-container.db",
         "modelerType" : "",
         "BLOCK_CACHE_MISS" : 6,
         "BLOCK_CACHE_HIT" : 29,
         "BLOCK_CACHE_ADD" : 6,
         "BLOCK_CACHE_ADD_FAILURES" : 0,
         "BLOCK_CACHE_INDEX_MISS" : 0,
         ...
     },
     ....
   #+end_src
*** (optional) 启动datanode的web服务
配置
#+begin_src xml
    <property>
      <name>hdds.datanode.http-address</name>
      <value>localhost:9882</value>
      <tag>HDDS, MANAGEMENT</tag>
      <description>
        The address and the base port where the Datanode web ui will listen on.
        If the port is 0 then the server will start on a free port.
      </description>
    </property>
    <property>
      <name>hdds.datanode.http-bind-host</name>
      <value>localhost</value>
      <tag>HDDS, MANAGEMENT</tag>
      <description>
        The actual address the Datanode web server will bind to. If this
        optional address is set, it overrides only the hostname portion of
        hdds.datanode.http-address.
      </description>
    </property>

#+end_src

***** jetty 依赖找不到
ozone NoClassDefFoundError: org/eclipse/jetty/server/ConnectionFactory
****** 原因
#+begin_src xml
  <!--注释掉一下几个scope为test的属性-->
  <!-- 在 container-service的pom中-->
      <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-hdds-hadoop-dependency-test</artifactId>
        <!--<scope>test</scope>-->
      </dependency>
      <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-hdfs</artifactId>
        <!--<scope>test</scope>-->
        <type>test-jar</type>
      </dependency>

      <!--在最外层pom中-->
      <dependency>
          <groupId>org.apache.hadoop</groupId>
          <artifactId>hadoop-hdds-hadoop-dependency-test</artifactId>
          <version>${hdds.version}</version>
          <!--<scope>test</scope>-->
        </dependency>
#+end_src
**** 与scm交互
使用 ScmDatanodeProtocl协议来与scm交互

#+begin_src text
  # 生成一个新的数据路径
  └── volumes
      ├── hdds
      │   ├── 043d1151-14a4-4e76-a667-267a24e3b99f
      │   └── VERSION
      └── scmUsed

  # 生成新的ratis组
  ├── ratis
  │   │   └── ae6096dd-84c9-4fae-8674-56c060fdc170
  │   │       ├── current
  │   │       │   ├── log_inprogress_0
  │   │       │   ├── raft-meta
  │   │       │   └── raft-meta.conf
  │   │       ├── in_use.lock
  │   │       └── sm


#+end_src

** ozone om

*** init
在配置中读取scm配置的ScmBlockLocationProtocol协议在scm上的服务,然后通过该协议问scm信息,包括集群id和scm id

然后在配置的本地元数据目录下写下该信息
#+begin_src text
  │   ├── om
  │   │   └── current
  │   │       └── VERSION


  # cat VERSION

  #Fri Oct 15 10:11:21 CST 2021
  nodeType=OM
  scmUuid=043d1151-14a4-4e76-a667-267a24e3b99f
  clusterID=CID-efcf1bf1-a78b-4d9d-a99d-d80ecb768602
  cTime=1634263881350
  omUuid=e8e5ca94-7f88-48e7-90ae-ee56493bdf86
  layoutVersion=0

#+end_src

*** 启动om
会在配置的om db目录下防止om rocksdb的数据

**** om系统表,结构如下
   * |----------------------------------------------------------------------|
   * |  Column Family     |        VALUE                                    |
   * |----------------------------------------------------------------------|
   * | userTable          |     /user->UserVolumeInfo                       |
   * |----------------------------------------------------------------------|
   * | volumeTable        |     /volume->VolumeInfo                         |
   * |----------------------------------------------------------------------|
   * | bucketTable        |     /volume/bucket-> BucketInfo                 |
   * |----------------------------------------------------------------------|
   * | keyTable           | /volumeName/bucketName/keyName->KeyInfo         |
   * |----------------------------------------------------------------------|
   * | deletedTable       | /volumeName/bucketName/keyName->RepeatedKeyInfo |
   * |----------------------------------------------------------------------|
   * | openKey            | /volumeName/bucketName/keyName/id->KeyInfo      |
   * |----------------------------------------------------------------------|
   * | s3SecretTable      | s3g_access_key_id -> s3Secret                   |
   * |----------------------------------------------------------------------|
   * | dTokenTable        | s3g_access_key_id -> s3Secret                   |
   * |----------------------------------------------------------------------|
   * | prefixInfoTable    | prefix -> PrefixInfo                            |
   * |----------------------------------------------------------------------|
   * |  multipartInfoTable| /volumeName/bucketName/keyName/uploadId ->...   |
   * |----------------------------------------------------------------------|
   * |----------------------------------------------------------------------|
   * |  transactionInfoTable | #TRANSACTIONINFO -> OMTransactionInfo        |
   * |----------------------------------------------------------------------|

** ozone 写入数据流程

*** ozone-client与hdds-container-services的交互
通过DatanodeClientProtocol.proto 这个协议,将数据组织成一个个chunk,封装为writeChunk(ContainerCommandRequestProto)
将数据内容和crc一同发往指定dn的指定container的指定block

**** 在datanode上如何将接收到的数据持久化存储起来的?


