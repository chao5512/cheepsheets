#+title: druid
* 设计 
1. 多进程
2. 易扩展
3. 容灾能力，某一个进程的崩溃不会立刻影响其他节点
** 架构
*** 节点角色
1. coordinator： 管理segement
2. overload： 数据摄取的工作分配
3. broker： 处理外部查询请求
4. router： 可选节点，可以将请求路由到其他节点，运行web控制台
5. historical： 存储可查询的数据
6. middleManager: 负责摄取数据
*** 外部依赖
**** deep storage
1. 用作数据备份
2. 用作数据传递的共享存储
3. historical在响应查询的时候应该是不访问深度存储的，他应该在查询前就欲拉取segments到本地磁盘，待验证：不过懒加载模式下，应该是query时才去加载
**** 元数据存储
1. 存储segment使用信息和任务信息
**** zookeeper
1. 服务发现
2. 协调
3. leader选举
*** 存储
**** datasource
1. 数据存储在datasource中，可以看作一张表，表中数据按时间分区
2. 每个分区被称为chunk
3. 每个chunk中，数据又被分区成为一个或多个segement
**** segment
***** middle manager
segment是在middlemanager上创建的，在middlemanager上时，它是可变的、未提交的
***** segment创建步骤
1. 转换为列式
2. Indexing：创建位图索引，并使用索引替换维度列
3. 压缩
   1. 对字符串的压缩
   2. 对位图索引的压缩
   3. 对所有拥有类型声明的列的压缩
***** segment周期的提交与发布
1. segment刷入deep storage
2. handoff: segment被托管给historical
3. 写入segment相关信息到元数据，用来决定加载或写在segment
****** Indexing过程
******* 需要在构建所以前确定segment的标识符
1. append模式,使用overload的allocate api来添加一个新的分区到一个已有的segments集合
2. overwrite模式，新的版本号，新的segment集合
******* 实时任务
支持实时查询，但是并没有发布到深度存储
******* index完成时
可以发布同时向元数据存储写入一条该segment相关数据
******* indexing完成后
如果indexing是个实时任务，那么它将等待historical节点加载该segment。不是实时任务则直接退出index阶段
******* 此时coordinator和historical的一面
1. coordinator周期的拉取元数据中新发布的segment
2. 发现新发布但是并未可用的segment，挑选一个historical并命令该historical节点加载segent并提供服务
3. historical节点干活
4. 这时如果index 任务还在等待handoff， 那么它可以退出了
****** segment identifier
datasource_intervalStart_intervalEnd_version_partitionNum
1. datasource name
2. Time interval，包含这个segment的chunk的时间段。对应对摄入任务的segmentGranularity，granularitySpec
3. version number
4. 分区号。ok now we can find any segment
***** segment lifecycle
****** 三个方面
******* 元数据存储
1. 向元数据存储写入一条segment记录的过程叫作pubulish
2. 这些记录又一个标志位used，代表是否可查
3. 实时摄取的segment会在被publish前就可以查询
******* 深度存储
segment一旦构造完成，立刻刷入深度存储中，然后写入meta存储
******* 支持可查
****** 查看segment
You can inspect the state of currently active segments using the Druid SQL sys.segments table. It includes the following flags:

is_published: True if segment metadata has been published to the metadata store and used is true.
is_available: True if the segment is currently available for querying, either on a realtime task or Historical process.
is_realtime: True if the segment is only available on realtime tasks. For datasources that use realtime ingestion, this will generally start off true and then become false as the segment is published and handed off.
is_overshadowed: True if the segment is published (with used set to true) and is fully overshadowed by some other published segments. Generally this is a transient state, and segments in this state will soon have their used flag automatically set to false.
**** segment的结构
1. 列式存储结构
2. ts列和metrics列
3. 维度列
   1. 值到id的对应关系字典
   2. 位图，对于某个值，标识哪些行包含它 最坏情况下，空间复杂度位行数*当前列可能的取值。为了减轻存储负担  可以用roaring bitmap compression.
   3. 将值替换位id的数据列表
***** why
In other words, queries that solely aggregate metrics based on filters do not need to touch the list of dimension values stored in (3)
**** files about segment
1. 00000.smoosh： 包含了所有列的文件和一个索引文件。放在一起以减少文件描述符的消耗
2. factory.json
3. meta.smoosh
4. version.bin
**** 列格式
1. jackson序列化的列描述符
2. 二进制的列值表
*** metadata
**** druid.metadata.storage.tables.segments表
1. 存储所有的used segment
2. coordinator使用这个表来决定可查询的segment
3. 主要的功能列有两列，剩下的主要用于indexing
   1. used： 标识segment是否应该可用
   2. payload ：一个json串，存储这个segment的元数据
**** rule table
segment的分配规则
**** config table
配置表，运行时修改配置的入口
**** Task-related tables
用于overload和middlemanager来保存任务信息
**** Audit table
历史审计表
*** lifeCycle
用来管理需要start和stop的对象
**** stages
***** 1. init
目前，这个阶段专门用于log4j初始化，因为几乎所有东西都需要日志记录，并且应该在最后关闭日志记录。任何一种bootstrapping对象，如果它提供了在几乎所有其他生命周期对象之前应该初始化的东西，那么它也可以属于这里(如果它在启动或停止期间不需要日志记录的话)。
***** 2. normal 
默认的，除了任何形式的服务器或服务声明之外，大多数对象在这个级别注册可能最有意义。
***** 3. server
这个生命周期阶段适用于所有的“服务器”对象，例如:org.apache.druid.server.initialization.jetty.JettyServerModule，但是任何类型的“服务器”，如果它希望大部分(或一些特定的)生命周期对象在它开始时被初始化，并且在它停止时仍然可用，那么它可以逻辑地生活在这个阶段
***** 4. ANNOUNCEMENTS
用来发布服务节点位置的对象属于这个阶段
*** 注册方式
*** router
web 控制台由router进程维护
*** storage
[[https://blog.bcmeng.com/post/druid-storage.html][Ref]]
* 算法
** bitmap
[[http://hbasefly.com/2018/06/19/timeseries-database-8/][hbaseFly]]
* utils
** lifecycle

* 用到的工具
** jackson
[[https://developer.ibm.com/zh/articles/jackson-advanced-application/][ibm-ref]]
